{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99592bf1-d3fd-465d-afa3-a6de25cb78bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a071116-8dd1-41d8-b736-e8a410f35159",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "import re\n",
    "import cobra\n",
    "import logging\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pubchempy as pcp\n",
    "from chemspipy import ChemSpider\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqUtils import molecular_weight\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "import yaml\n",
    "from typing import List\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "pubchem_columns = [\"cid\", \"cmpdname\", \"cmpdsynonym\", \"smiles\"]\n",
    "pubchemdb = pd.read_csv(\"PubChem_compound_all_pathways.csv\", usecols=pubchem_columns)\n",
    "\n",
    "inputs_path = \"/home/kubeflow/ecgems/analyses/iML1515/inputs\"\n",
    "\n",
    "if not inputs_path:\n",
    "    inputs_path = os.getenv(\"INPUTS\")  # From your env.sh file\n",
    "    if inputs_path is None:\n",
    "        raise ValueError(\"The INPUTS environment variable is not set.\")\n",
    "\n",
    "inputs_file = os.path.join(inputs_path, \"inputs.yml\")\n",
    "if not os.path.isfile(inputs_file):\n",
    "    raise FileNotFoundError(\n",
    "        f\"The 'inputs.yml' file could not be found at {inputs_file}.\"\n",
    "    )\n",
    "\n",
    "with open(inputs_file, \"r\") as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "strain = data[\"strain\"]\n",
    "species = data[\"species\"]\n",
    "chem_spider_key = data[\"chem_spider_key\"]\n",
    "cs = ChemSpider(chem_spider_key)\n",
    "\n",
    "# Input and output file paths\n",
    "sbml_model = os.path.join(inputs_path, data[\"sbml_model\"])\n",
    "output_file_path = os.path.join(inputs_path, data[\"output_file_path\"])\n",
    "os.makedirs(output_file_path, exist_ok=True)\n",
    "if data[\"protein_file_path\"]:\n",
    "    protein_file_path = os.path.join(inputs_path, data[\"protein_file_path\"])\n",
    "else:\n",
    "    protein_file_path = None\n",
    "\n",
    "cofactors = data[\"cofactors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5dd195",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "logging.getLogger(\"cobra\").setLevel(logging.ERROR)\n",
    "model = cobra.io.read_sbml_model(sbml_model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c861fb-1530-413e-baa4-b6c830136d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a locks for accessing data structures\n",
    "batch_updates_lock = threading.Lock()\n",
    "processed_values_lock = threading.Lock()\n",
    "\n",
    "\n",
    "def batch_loop_setup(file_to_update, df_columns, column_key):\n",
    "    # Check if checkpointing activated\n",
    "    if os.path.exists(file_to_update):\n",
    "        # Read in data, and update list of already processed\n",
    "        values_df = pd.read_csv(file_to_update)\n",
    "        processed_values = set(values_df[column_key].unique())\n",
    "    else:\n",
    "        # Set up empty data frame and empty set of already processed\n",
    "        values_df = pd.DataFrame(columns=df_columns)\n",
    "        processed_values = set()\n",
    "\n",
    "    # Process in batches\n",
    "    batch_updates = []\n",
    "    batch_size = 200\n",
    "    return values_df, processed_values, batch_updates, batch_size\n",
    "\n",
    "\n",
    "\"\"\"Reusable function to run in parallel for various IO tasks\"\"\"\n",
    "\n",
    "\n",
    "def process_futures(\n",
    "    futures,\n",
    "    values_df,\n",
    "    processed_values,\n",
    "    column_key,\n",
    "    batch_updates,\n",
    "    batch_size,\n",
    "    file_to_update,\n",
    "):\n",
    "    try:\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                with batch_updates_lock:\n",
    "                    batch_updates.append(result)\n",
    "                with processed_values_lock:\n",
    "                    processed_values.add(result[column_key])\n",
    "\n",
    "                # Check if batch size is reached\n",
    "                if len(batch_updates) >= batch_size:\n",
    "                    with batch_updates_lock:\n",
    "                        if len(batch_updates) >= batch_size:\n",
    "                            # Convert batch updates to DataFrame\n",
    "                            batch_df = pd.DataFrame(batch_updates)\n",
    "                            # Append batch updates to the main DataFrame and save\n",
    "                            values_df = pd.concat(\n",
    "                                [values_df.astype(batch_df.dtypes), batch_df],\n",
    "                                ignore_index=True,\n",
    "                            )\n",
    "                            values_df.to_csv(file_to_update, index=False)\n",
    "                            # Clear batch updates after saving\n",
    "                            batch_updates = []\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {result[column_key]}: {e}\")\n",
    "\n",
    "    # After the loop, check if there are any remaining updates not yet saved\n",
    "    if batch_updates:\n",
    "        with batch_updates_lock:\n",
    "            if batch_updates:\n",
    "                batch_df = pd.DataFrame(batch_updates)\n",
    "                values_df = pd.concat(\n",
    "                    [values_df.astype(batch_df.dtypes), batch_df], ignore_index=True\n",
    "                )\n",
    "                values_df.to_csv(file_to_update, index=False)\n",
    "\n",
    "def get_smiles_from_csv_apis(name):\n",
    "    try:\n",
    "        # First, search in the 'cmpdname' column for an exact match\n",
    "        result = pubchemdb[pubchemdb[\"cmpdname\"] == name]\n",
    "        # If a match is found, return the 'smiles' for the match\n",
    "        if not result.empty:\n",
    "            try:\n",
    "                cid = result[\"cid\"].values[0]\n",
    "                smiles = result[\"smiles\"].values[0]\n",
    "                if DEBUG:\n",
    "                    print(f\"CSV cid: {cid} name: {name} smile: {smiles}\")\n",
    "                return smiles\n",
    "            except Exception as e:\n",
    "                print(f\"Error while processing 'cmpdname' match: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while searching 'cmpdname': {e}\")\n",
    "\n",
    "    try:\n",
    "        # Search in 'cmpdsynonym' column using vectorized operations for speed\n",
    "        mask = pubchemdb[\"cmpdsynonym\"].str.contains(\n",
    "            rf\"(?:^|\\|){re.escape(name)}(?:\\||$)\", na=False, regex=True\n",
    "        )\n",
    "        result = pubchemdb[mask]\n",
    "        # If a match is found, return the 'smiles' for the match\n",
    "        if not result.empty:\n",
    "            try:\n",
    "                cid = result[\"cid\"].values[0]\n",
    "                smiles = result[\"smiles\"].values[0]\n",
    "                if DEBUG:\n",
    "                    print(f\"SYNONYM cid: {cid} name: {name} smile: {smiles}\")\n",
    "                return smiles\n",
    "            except Exception as e:\n",
    "                print(f\"Error while processing 'cmpdsynonym' match: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while searching 'cmpdsynonym': {e}\")\n",
    "\n",
    "    try:\n",
    "        # Looking for corresponding metabolite smiles using the PubChem API\n",
    "        compounds = pcp.get_compounds(name, \"name\")\n",
    "        if len(compounds) > 0:\n",
    "            try:\n",
    "                smiles = compounds[0].isomeric_smiles\n",
    "                if DEBUG:\n",
    "                    print(f\"API name: {name} smile: {smiles}\")\n",
    "                return smiles\n",
    "            except Exception as e:\n",
    "                print(f\"Error while processing PubChem API response: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while querying PubChem API: {e}\")\n",
    "\n",
    "    # try:\n",
    "    #     # Looking for corresponding metabolite smiles using the ChemSpider API\n",
    "    #     simple_name = remove_characters_within_brackets(name)\n",
    "    #     results = cs.search(simple_name)\n",
    "    #     if results:\n",
    "    #         try:\n",
    "    #             smiles = results[0].smiles\n",
    "    #             if DEBUG:\n",
    "    #                 print(f\"SPIDER name: {name} smile: {smiles}\")\n",
    "    #             return smiles\n",
    "    #         except Exception as e:\n",
    "    #             print(f\"Error while processing ChemSpider API response: {e}\")\n",
    "    #     print(f\"SMILE NOT FOUND FOR name: {name} simple name: {simple_name}\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error while querying ChemSpider API: {e}\")\n",
    "\n",
    "    # If no match is found\n",
    "    return \"Compound not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb51ce-8f97-4e28-a7d6-348614387651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_characters_within_brackets(text):\n",
    "    # Pattern to match content within brackets (including the brackets themselves)\n",
    "    pattern = r\"\\s*\\([^)]*\\)\"\n",
    "    # Replace matched content with an empty string\n",
    "    cleaned_text = re.sub(pattern, \"\", text)\n",
    "    return cleaned_text\n",
    "\n",
    "def get_accession(query, target_id):\n",
    "    url = \"https://rest.uniprot.org/uniprotkb/stream\"\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"format\": \"json\",\n",
    "        \"fields\": \"accession,ec,mass,gene_names,lineage,organism_name,sequence\",\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        uniprot_response = requests.get(url, params=params).json()\n",
    "        if not uniprot_response.get(\"results\"):\n",
    "            return None, None, None, None\n",
    "\n",
    "        for result in uniprot_response[\"results\"]:\n",
    "            if \"genes\" not in result:\n",
    "                continue\n",
    "\n",
    "            # Check if this result contains our target gene\n",
    "            found = False\n",
    "            for gene in result[\"genes\"]:\n",
    "                # Check main gene name\n",
    "                if \"geneName\" in gene and gene[\"geneName\"][\"value\"] == target_id:\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "                # Check synonyms\n",
    "                if \"synonyms\" in gene:\n",
    "                    for synonym in gene[\"synonyms\"]:\n",
    "                        if synonym[\"value\"] == target_id:\n",
    "                            found = True\n",
    "                            break\n",
    "                if found:\n",
    "                    break\n",
    "\n",
    "            if not found:\n",
    "                continue\n",
    "\n",
    "            # If we found the target gene, extract all needed data from this result\n",
    "            accession = result[\"primaryAccession\"]\n",
    "\n",
    "            # Get molecular weight and sequence\n",
    "            mass = result[\"sequence\"][\"molWeight\"] if \"sequence\" in result else None\n",
    "            seq = result[\"sequence\"][\"value\"] if \"sequence\" in result else None\n",
    "\n",
    "            # Extract EC number\n",
    "            ec = None\n",
    "            if \"proteinDescription\" in result:\n",
    "                protein_desc = result[\"proteinDescription\"]\n",
    "                if (\n",
    "                    \"recommendedName\" in protein_desc\n",
    "                    and \"ecNumbers\" in protein_desc[\"recommendedName\"]\n",
    "                ):\n",
    "                    ec_numbers = protein_desc[\"recommendedName\"][\"ecNumbers\"]\n",
    "                    if ec_numbers:\n",
    "                        ec = ec_numbers[0][\"value\"]\n",
    "                elif (\n",
    "                    \"includes\" in protein_desc\n",
    "                    and \"recommendedName\" in protein_desc[\"includes\"]\n",
    "                ):\n",
    "                    includes_rec = protein_desc[\"includes\"][\"recommendedName\"]\n",
    "                    if \"ecNumbers\" in includes_rec and includes_rec[\"ecNumbers\"]:\n",
    "                        ec = includes_rec[\"ecNumbers\"][0][\"value\"]\n",
    "\n",
    "            return accession, mass, ec, seq\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing response: {e}\")\n",
    "\n",
    "    return None, None, None, None\n",
    "\n",
    "# extra = ['umpH', 'ldtB', 'ldtD', 'ldtC', 'pfo', 'glsB',\n",
    "#          'ldtE', 'ldtA', 'wbbH', 'wzxB', 'umpG', 'fau',\n",
    "#          'gpmM'\n",
    "#         ]\n",
    "\n",
    "def process_uniprot_gene(gene):\n",
    "    gene_name = gene.name\n",
    "\n",
    "    pattern = r\"^G_.*_\\d+$\"\n",
    "\n",
    "    if re.match(pattern, gene_name):\n",
    "        # Remove the 'G_' prefix and replace '_<integer>' with '.<integer>'\n",
    "        gene_name = re.sub(r\"^G_(.*)_(\\d+)$\", r\"\\1.\\2\", gene_name)\n",
    "\n",
    "    if gene_name not in processed_genes:\n",
    "        try:\n",
    "            # Try with strain first\n",
    "            query = f'(organism_name:\"{species}\" AND strain:\"{strain}\") AND {gene_name}'\n",
    "            organism = strain\n",
    "            accession, mass, ec, seq = get_accession(query, gene_name)\n",
    "            if seq is None:\n",
    "                print(f\"Sequence for strain {organism} and {gene_name} is none\")\n",
    "                # Then try with species\n",
    "                query = f'(organism_name:\"{species}\") AND {gene_name}'\n",
    "                organism = species\n",
    "                accession, mass, ec, seq = get_accession(query, gene_name)\n",
    "                if seq is None:\n",
    "                    print(f\"Sequence for strain {organism} and {gene_name} is none\")\n",
    "                    return None\n",
    "            return {\n",
    "                \"Gene ID\": gene.id,\n",
    "                \"Gene name\": gene.name,\n",
    "                \"Accession\": accession,\n",
    "                \"Sequence\": seq,\n",
    "                \"Mass\": mass,\n",
    "                \"EC number\": ec,\n",
    "                \"Organism\": organism,\n",
    "                \"Gene reactions\": [r.id for r in gene.reactions],\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {gene_name}: {e}\")\n",
    "\n",
    "def process_metabolite_model(m):\n",
    "    if m.id not in processed_metabolites:\n",
    "        name = m.name\n",
    "        if m.formula is not None and m.formula in name:\n",
    "            name = name.replace(m.formula, \"\")\n",
    "        try:\n",
    "            # Looking for corresponding metabolite smiles in PubChem CSV / API and ChemSpider\n",
    "            smiles = get_smiles_from_csv_apis(name)\n",
    "\n",
    "            if smiles is None:\n",
    "                smiles = \"Compound not found\"\n",
    "            elif smiles == \"\":\n",
    "                print(\"NAN smiles\")\n",
    "                smiles = \"Compound not found\"\n",
    "\n",
    "            # Collect data for batch update\n",
    "            return {\"metabolite_id\": m.id, \"name\": m.name, \"smiles\": smiles}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {m.id}: {e}\")\n",
    "            # Handle error (e.g., log it, attempt to recover, skip this metabolite, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce053d28-e648-4647-8cbe-55ceea0193e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if protein_file_path:\n",
    "    \"\"\"Gene-sequence retrieval from fasta file\"\"\"\n",
    "    file_to_update = os.path.join(output_file_path, \"gene_sequence_data.csv\")\n",
    "    columns: List[str] = [\n",
    "        \"Gene ID\",\n",
    "        \"Gene name\",\n",
    "        \"Accession\",\n",
    "        \"Sequence\",\n",
    "        \"Mass\",\n",
    "        \"EC number\",\n",
    "        \"Organism\",\n",
    "        \"Gene reactions\",\n",
    "    ]\n",
    "    genes_df = pd.DataFrame(columns)\n",
    "    records = []\n",
    "    for record in SeqIO.parse(protein_file_path, \"fasta\"):\n",
    "        records.append(record)\n",
    "    genes = []\n",
    "    for gene in model.genes:\n",
    "        gene.id = gene.id.replace(\"_\", \".\")\n",
    "        genes.append(gene)\n",
    "    intersections = [\n",
    "        (record, gene)\n",
    "        for record in records\n",
    "        if any(record.id == gene.id for gene in genes)\n",
    "    ]\n",
    "\n",
    "    data = []\n",
    "    for r_g_pair in intersections:\n",
    "        record = r_g_pair[0]\n",
    "        gene = r_g_pair[1]\n",
    "        sequence = str(record.seq)\n",
    "        mass = molecular_weight(sequence, seq_type=\"protein\")\n",
    "        data.append(\n",
    "            {\n",
    "                \"Gene ID\": record.id,\n",
    "                \"Gene name\": record.id,\n",
    "                \"Accession\": None,\n",
    "                \"Sequence\": sequence,\n",
    "                \"Mass\": mass,\n",
    "                \"EC number\": None,\n",
    "                \"Organism\": None,\n",
    "                \"Gene reactions\": [r.id for r in gene.reactions],\n",
    "            }\n",
    "        )\n",
    "    genes_df = pd.DataFrame(data)\n",
    "    genes_df.to_csv(file_to_update, index=False)\n",
    "\n",
    "else:\n",
    "    \"\"\"Gene-sequence retrieval from UniProt\"\"\"\n",
    "    # Initialise checkpointing\n",
    "    file_to_update = os.path.join(output_file_path, \"gene_sequence_data.csv\")\n",
    "    df_columns = [\n",
    "        \"Gene ID\",\n",
    "        \"Gene name\",\n",
    "        \"Accession\",\n",
    "        \"Sequence\",\n",
    "        \"Mass\",\n",
    "        \"EC number\",\n",
    "        \"Organism\",\n",
    "        \"Gene reactions\",\n",
    "    ]\n",
    "    column_key = \"Gene name\"\n",
    "    genes_df, processed_genes, batch_updates, batch_size = batch_loop_setup(\n",
    "        file_to_update, df_columns, column_key\n",
    "    )\n",
    "    batch_size = 100\n",
    "    num_cpus = min(os.cpu_count(), 16)\n",
    "    with ThreadPoolExecutor(max_workers=num_cpus) as executor:\n",
    "        futures = {\n",
    "            executor.submit(process_uniprot_gene, gene): gene for gene in model.genes\n",
    "        }\n",
    "        process_futures(\n",
    "            futures,\n",
    "            genes_df,\n",
    "            processed_genes,\n",
    "            column_key,\n",
    "            batch_updates,\n",
    "            batch_size,\n",
    "            file_to_update,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8815b07e-5bc3-4d3d-9c50-08fd2c96a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\"\"\"Metabolite-SMILES retrieval\"\"\"\n",
    "for _ in range(1):  # Loop runs twice (0 and 1)\n",
    "    # Paths\n",
    "    file_to_update = os.path.join(output_file_path, \"metabolite_smiles_data.csv\")\n",
    "    df_columns = [\"metabolite_id\", \"name\", \"smiles\"]\n",
    "    column_key = \"metabolite_id\"\n",
    "    metabolites_df, processed_metabolites, batch_updates, batch_size = batch_loop_setup(\n",
    "        file_to_update, df_columns, column_key\n",
    "    )\n",
    "    API_counter = [0]\n",
    "    API_counter[0] = 0\n",
    "    API_test = \"10-Formyltetrahydrofolate\"\n",
    "\n",
    "    batch_size = 100\n",
    "    with ThreadPoolExecutor(max_workers=32) as executor:\n",
    "        futures = {\n",
    "            executor.submit(process_metabolite_model, m): m for m in model.metabolites\n",
    "        }\n",
    "        process_futures(\n",
    "            futures,\n",
    "            metabolites_df,\n",
    "            processed_metabolites,\n",
    "            column_key,\n",
    "            batch_updates,\n",
    "            batch_size,\n",
    "            file_to_update,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90a4db5-feb7-4bf4-8c3f-559834b227ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "Pair sequences with adequate substrate SMILES\n",
    "\"\"\"\n",
    "\n",
    "# metabolites that should not be considered main substrates of reactions\n",
    "metabolite_smiles_path = os.path.join(output_file_path, \"metabolite_smiles_data.csv\")\n",
    "gene_sequence_path = os.path.join(output_file_path, \"gene_sequence_data.csv\")\n",
    "\n",
    "# Load data and ensure files are readable\n",
    "try:\n",
    "    metabolites_df = pd.read_csv(metabolite_smiles_path, index_col=\"metabolite_id\")\n",
    "    genes_df = pd.read_csv(gene_sequence_path, index_col=\"Gene ID\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "    raise\n",
    "\n",
    "seqs_smiles = []\n",
    "missing_gene_ids = []\n",
    "missing_metabolite_ids = []\n",
    "\n",
    "\n",
    "for gene in model.genes:\n",
    "    if gene.id == \"spontaneous\":\n",
    "        continue\n",
    "    gene_id = gene.id\n",
    "\n",
    "    # Regular expression pattern\n",
    "    pattern = r\"^G_.*_\\d+$\"\n",
    "\n",
    "    # Check if the variable matches the pattern\n",
    "    if re.match(pattern, gene_id):\n",
    "        # Remove the 'G_' prefix and replace '_<integer>' with '.<integer>'\n",
    "        gene_id = re.sub(r\"^G_(.*)_(\\d+)$\", r\"\\1.\\2\", gene_id)\n",
    "\n",
    "    try:\n",
    "        sequence = genes_df.loc[gene_id, \"Sequence\"]\n",
    "        mass = genes_df.loc[gene_id, \"Mass\"]\n",
    "        ec = genes_df.loc[gene_id, \"EC number\"]\n",
    "    except KeyError:\n",
    "        print(f\"Gene ID {gene_id} is missing in gene_sequence_data.csv\")\n",
    "        missing_gene_ids.append(gene_id)\n",
    "        continue\n",
    "\n",
    "    for r in gene.reactions:\n",
    "        reactants = [(m.name, m.id) for m in r.reactants if m.name not in cofactors]\n",
    "        for i in reactants:\n",
    "            try:\n",
    "                smiles = metabolites_df.loc[i[1], \"smiles\"]\n",
    "            except KeyError:\n",
    "                print(f\"Metabolite ID {i[1]} is missing in metabolite_smiles_data.csv\")\n",
    "                missing_metabolite_ids.append(i[1])\n",
    "                continue\n",
    "\n",
    "            seqs_smiles.append(\n",
    "                {\n",
    "                    \"Gene ID\": gene_id,\n",
    "                    \"Gene name\": gene.name,\n",
    "                    \"Sequence\": sequence,\n",
    "                    \"Reaction ID\": r.id,\n",
    "                    \"Reaction name\": r.name,\n",
    "                    \"Reaction\": r.reaction,\n",
    "                    \"Direction\": \"Forward\",\n",
    "                    \"Substrate Name\": i[0],\n",
    "                    \"Substrate ID\": i[1],\n",
    "                    \"Substrate Smiles\": smiles,\n",
    "                    \"Kcat\": \"\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "        if r.reversibility:\n",
    "            products = [(m.name, m.id) for m in r.products if m.name not in cofactors]\n",
    "            for i in products:\n",
    "                try:\n",
    "                    smiles = metabolites_df.loc[i[1], \"smiles\"]\n",
    "                except KeyError:\n",
    "                    print(\n",
    "                        f\"Metabolite ID {i[1]} is missing in metabolite_smiles_data.csv\"\n",
    "                    )\n",
    "                    missing_metabolite_ids.append(i[1])\n",
    "                    continue\n",
    "\n",
    "                seqs_smiles.append(\n",
    "                    {\n",
    "                        \"Gene ID\": gene_id,\n",
    "                        \"Gene name\": gene.name,\n",
    "                        \"Sequence\": sequence,\n",
    "                        \"Reaction ID\": r.id,\n",
    "                        \"Reaction name\": r.name,\n",
    "                        \"Reaction\": r.reaction,\n",
    "                        \"Direction\": \"Reverse\",\n",
    "                        \"Substrate Name\": i[0],\n",
    "                        \"Substrate ID\": i[1],\n",
    "                        \"Substrate Smiles\": smiles,\n",
    "                        \"Kcat\": \"\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "# Convert to DataFrame and save to CSV\n",
    "seqs_smiles_df = pd.DataFrame(seqs_smiles)\n",
    "seqs_smiles_df.to_csv(\n",
    "    os.path.join(output_file_path, \"sequences_smiles.csv\"), index=False\n",
    ")\n",
    "\n",
    "# Log missing gene and metabolite IDs\n",
    "if missing_gene_ids:\n",
    "    print(\n",
    "        f\"Warning: The following gene IDs were not found in gene_sequence_data.csv: {set(missing_gene_ids)}\"\n",
    "    )\n",
    "\n",
    "if missing_metabolite_ids:\n",
    "    print(\n",
    "        f\"Warning: The following metabolite IDs were not found in metabolite_smiles_data.csv: {set(missing_metabolite_ids)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d33e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f'Total execution time: {elapsed_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea77c97-4200-4e76-8386-5ec838480b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecGEMs",
   "language": "python",
   "name": "ecgems"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
