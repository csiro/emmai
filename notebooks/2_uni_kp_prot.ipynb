{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df267f-ce6e-4ef6-828e-68d68d1ba90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9581321-aa3c-44b0-b1dc-49f8ac0d6844",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import torch\n",
    "import warnings\n",
    "# build_vocab, pretrain_trfm, utils packages are from SMILES Transformer\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "# transformers package is from ProtTrans\n",
    "import re\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import yaml\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "# Define your custom path here, e.g., \"custom/path/to/inputs.yml\"\n",
    "inputs_path = \"../../analyses/iML1515/inputs\"\n",
    "notebook_dir = Path().resolve()\n",
    "\n",
    "# If inputs_path is empty, use the INPUTS environment variable\n",
    "if not inputs_path:\n",
    "    inputs_path = os.getenv(\"INPUTS\")\n",
    "    if inputs_path is None:\n",
    "        raise ValueError(\"The INPUTS environment variable is not set.\")\n",
    "\n",
    "inputs_file = os.path.join(inputs_path, \"inputs.yml\")\n",
    "if not os.path.isfile(inputs_file):\n",
    "    raise FileNotFoundError(f\"The 'inputs.yml' file could not be found at {inputs_file}.\")\n",
    "\n",
    "with open(inputs_file, \"r\") as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "sbml_model = data[\"sbml_model\"]\n",
    "test_path = data[\"output_file_path\"]\n",
    "model_path = (notebook_dir / data[\"unikp_path\"]).resolve()\n",
    "\n",
    "sys.path.append(model_path)\n",
    "from build_vocab import WordVocab\n",
    "from utils import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dc471e-b809-42c3-8ab6-797f3e4a543f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "seqs_smiles_df = pd.read_csv(os.path.join(test_path, 'sequences_smiles.csv'))\n",
    "\n",
    "with open(os.path.join(model_path, 'UniKP for kcat.pkl'), \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "batch = 0\n",
    "batch_len = 20\n",
    "\n",
    "predicted_pair = {}\n",
    "\n",
    "# Function to check if a pair of Substrate Smiles and Sequence has been assessed\n",
    "def is_assessed(substrate_smiles, sequence):\n",
    "    return (substrate_smiles, sequence) in predicted_pair\n",
    "\n",
    "# Function to check if reaction is a transport reaction\n",
    "transporters = ['transport', 'symporter', 'diffusion', 'antiport', 'tranposrt']\n",
    "def contains_keywords(cell):\n",
    "    return any(keyword.lower() in str(cell).lower() for keyword in transporters)\n",
    "\n",
    "# Collect sequences and smiles in batches\n",
    "sequences = []\n",
    "smiles = []\n",
    "indices = []\n",
    "\n",
    "for index, row in seqs_smiles_df.iterrows():\n",
    "    if type(row['Sequence']) != float and not contains_keywords(row['Reaction name']) and np.isnan(row['Kcat']):\n",
    "        if row['Substrate Smiles'] != 'Compound not found':\n",
    "            pair_key = (row['Substrate Smiles'], row['Sequence'])\n",
    "            if is_assessed(*pair_key):\n",
    "                seqs_smiles_df.at[index, 'Kcat'] = predicted_pair[pair_key]\n",
    "            else:\n",
    "                print(row['Reaction ID'])\n",
    "                sequences.append(row['Sequence'])\n",
    "                smiles.append(row['Substrate Smiles'])\n",
    "                indices.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb94474-599c-4370-b731-ee0fdc2d15a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def process_sequence(seq):\n",
    "    if len(seq) > 1000:\n",
    "        return seq[:500] + seq[-500:]\n",
    "    return seq\n",
    "\n",
    "def Seq_to_vec(Sequence):\n",
    "    sequences_Example = [' '.join(process_sequence(seq)) for seq in Sequence]\n",
    "    num_sequences = len(sequences_Example)\n",
    "    #print(\"Processed sequences:\", sequences_Example)\n",
    "\n",
    "    tokenizer = T5Tokenizer.from_pretrained(os.path.join(model_path, 'prot_t5_xl_uniref50'), do_lower_case=False)\n",
    "    model = T5EncoderModel.from_pretrained(os.path.join(model_path, 'prot_t5_xl_uniref50'))\n",
    "    gc.collect()\n",
    "    print(\"Tokenizer and model loaded.\")\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        batch_size = min(num_sequences, torch.cuda.device_count() * 8)  # Adjust batch size for multiple GPUs\n",
    "    else:\n",
    "        print(\"Let's use\", os.cpu_count(), \"CPUs!\")\n",
    "        batch_size = min(num_sequences, os.cpu_count())\n",
    "    model = model.to(device).eval()\n",
    "    print(\"Model moved to device and set to evaluation mode.\")\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for i in range(0, num_sequences, batch_size):\n",
    "        print('Processing sequences from', str(i), 'to', str(i + batch_size))\n",
    "        batch_sequences = sequences_Example[i:i + batch_size]\n",
    "        batch_ids = tokenizer.batch_encode_plus(batch_sequences, add_special_tokens=True, padding=True)\n",
    "        input_ids = torch.tensor(batch_ids['input_ids']).to(device)\n",
    "        attention_mask = torch.tensor(batch_ids['attention_mask']).to(device)\n",
    "        #print(\"Batch input IDs:\", input_ids)\n",
    "        #print(\"Batch attention mask:\", attention_mask)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embedding = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        embedding = embedding.last_hidden_state\n",
    "        for seq_num in range(embedding.size(0)):\n",
    "            seq_len = (attention_mask[seq_num] == 1).sum()\n",
    "            seq_emd = embedding[seq_num][:seq_len - 1]\n",
    "            features.append(seq_emd)\n",
    "        #print(\"Batch embeddings:\", embedding)\n",
    "\n",
    "\n",
    "    print(\"Finished processing sequences.\")\n",
    "    return features\n",
    "\n",
    "# Process all sequences and smiles in one go\n",
    "if sequences:\n",
    "    features = Seq_to_vec(sequences)\n",
    "    #print(\"Features:\", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c6d674-5915-4564-8eb0-855fc0844e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def normalize_feature(features):\n",
    "    # Perform normalization directly on the GPU\n",
    "    features_normalize = torch.stack([f.mean(dim=0) for f in features], dim=0)\n",
    "    #print(\"Normalized features (GPU):\", features_normalize)\n",
    "\n",
    "    # Move features_normalize back to CPU if needed\n",
    "    features_normalize = features_normalize.cpu().numpy()\n",
    "    #print(\"Normalized features (CPU):\", features_normalize)\n",
    "    return features_normalize\n",
    "\n",
    "if features:\n",
    "    seq_vecs = normalize_feature(features)\n",
    "    #print(\"Sequence vectors:\", seq_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0573179f-5016-4f0c-a7fc-b145cb096608",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from pretrain_trfm import TrfmSeq2seq\n",
    "\n",
    "def smiles_to_vec(Smiles, vocab, device, trfm):\n",
    "    pad_index = 0\n",
    "    unk_index = 1\n",
    "    eos_index = 2\n",
    "    sos_index = 3\n",
    "    mask_index = 4\n",
    "\n",
    "    def get_inputs(sm):\n",
    "        seq_len = 220\n",
    "        sm = sm.split()\n",
    "        if len(sm)>218:\n",
    "            print('SMILES is too long ({:d})'.format(len(sm)))\n",
    "            sm = sm[:109]+sm[-109:]\n",
    "        ids = [vocab.stoi.get(token, unk_index) for token in sm]\n",
    "        ids = [sos_index] + ids + [eos_index]\n",
    "        seg = [1]*len(ids)\n",
    "        padding = [pad_index]*(seq_len - len(ids))\n",
    "        ids.extend(padding), seg.extend(padding)\n",
    "        return ids, seg\n",
    "\n",
    "    def get_array(smiles):\n",
    "        x_id, x_seg = [], []\n",
    "        for sm in smiles:\n",
    "            a, b = get_inputs(sm)\n",
    "            x_id.append(a)\n",
    "            x_seg.append(b)\n",
    "        #print(\"Input arrays created:\\nIDs:\", x_id, \"\\nSegments:\", x_seg)\n",
    "        return torch.tensor(x_id).to(device), torch.tensor(x_seg).to(device)\n",
    "\n",
    "    x_split = [split(sm) for sm in Smiles]\n",
    "    xid, xseg = get_array(x_split)\n",
    "    #print(\"SMILES split and converted to tensors:\\nXID:\", xid, \"\\nXSEG:\", xseg)\n",
    "    X = trfm.encode(torch.t(xid).to(device))\n",
    "    #print(\"Encoding complete:\\nEncoded Tensor:\", X)\n",
    "    return X.squeeze(0)\n",
    "\n",
    "if smiles:\n",
    "    #print(\"SMILES:\", smiles)\n",
    "    vocab = WordVocab.load_vocab(os.path.join(model_path, 'vocab.pkl'))\n",
    "    #print(\"Vocabulary loaded:\", vocab.stoi)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    trfm = TrfmSeq2seq(len(vocab), 256, len(vocab), 4)\n",
    "    # Use map_location to ensure the model is loaded on the device if GPU is not available\n",
    "    trfm.load_state_dict(torch.load(os.path.join(model_path, 'trfm_12_23000.pkl'), map_location=device))\n",
    "    trfm.to(device)\n",
    "    trfm.eval()\n",
    "    print(\"Transformer model loaded and set to evaluation mode.\")\n",
    "\n",
    "    smiles_vecs = [smiles_to_vec([sm], vocab, device, trfm) for sm in smiles]\n",
    "    #print(\"SMILES vectors:\", smiles_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb32f73f-dc3d-4e6a-85da-812e9c49e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(smiles_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df89d348-47b6-4dd0-89a8-3ddc4d32f8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sequences and smiles:\n",
    "    %time fused_vectors = np.concatenate((smiles_vecs, seq_vecs), axis=1)\n",
    "    print(\"fused_vectors time above\")\n",
    "    %time pre_kcats = model.predict(fused_vectors)\n",
    "    pd.DataFrame(pre_kcats)\n",
    "    print(\"pre_kcats time above\")\n",
    "    %time kcates = [math.pow(10, pre_kcats[i]) for i in range(len(pre_kcats))]\n",
    "    pd.DataFrame(kcates)\n",
    "    print(\"kcates time above\")\n",
    "\n",
    "    for i, index in enumerate(indices):\n",
    "        seqs_smiles_df.at[index, 'Kcat'] = kcates[i]\n",
    "        pair_key = (smiles[i], sequences[i])\n",
    "        predicted_pair[pair_key] = kcates[i]\n",
    "\n",
    "    # Save the DataFrame periodically\n",
    "    batch += 1\n",
    "    if batch == batch_len:\n",
    "        seqs_smiles_df.to_csv(os.path.join(test_path, 'sequences_smiles_complete.csv'), index=False)\n",
    "        batch = 0\n",
    "\n",
    "seqs_smiles_df.to_csv(os.path.join(test_path, 'sequences_smiles_complete.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c362782-eb2b-47d1-b228-f571c8e84951",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f'Total execution time: {elapsed_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3b2ade-d301-4263-809e-07c43870eaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecGEMs",
   "language": "python",
   "name": "ecgems"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
